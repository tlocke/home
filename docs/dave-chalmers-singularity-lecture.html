<!DOCTYPE html>
<html lang="en">
  <head>
        <title>Tony Locke - Dave Chalmers Singularity Lecture</title>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <link rel="stylesheet" href="/theme/css/main.css" />
      <link rel=icon href=/theme/images/icons/favicon.png sizes="16x16" type="image/png">
      <meta name="generator" content="Pelican" />
      <link href="https://www.tlocke.org.uk/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Tony Locke Full Atom Feed" />





  </head>

  <body id="index" class="home">
      <nav id="menu">
        <ul>
          <li><a href="/">Tony Locke</a>            <a href="/feeds/all.atom.xml"><img src="/theme/images/icons/atom.png" /></a>
          </li>

              <li><a href="/archives.html">Archive</a></li>
              <li><a href="https://github.com/tlocke">GitHub</a></li>
        </ul>
      </nav><!-- /#menu -->
  <article>
    <header>
      <h2 class="entry-title">
        Dave Chalmers Singularity Lecture
      </h2>
      
      <time class="published" datetime="2010-06-11T21:32:00+01:00">
        Fri 11 June 2010
      </time>
    </header>
    <p>A few weeks ago I went to Oxford to say hello to my friend Matt, and we went to a lecture on the <a href="http://en.wikipedia.org/wiki/Technological_singularity">singularity</a> by <a href="http://en.wikipedia.org/wiki/David_Chalmers">David Chalmers</a>. He covered many aspects, but one idea he talked about was that for safety reasons a superhuman AI should be developed in virtual reality. He said that the most important thing was that information shouldn't be allowed to leak in. Leaking out was less dangerous. A bit like the one-way mirrors they have in police interview rooms. The argument was that if information could leak out, people on the outside could be manipulated by the AI to free it.</p>
<p>An interesting idea, but I'm sceptical that we really can develop AIs safely. Perhaps the best we can do is to try to instil a moral principle that the strong shouldn't harm the weak. Since today's strong will be tomorrow's weak, as AIs gain in sophistication it should be in the strong's interest to uphold this principle. The problem is that it's a principle that can never be enforced by the weak, and so we'll always have to rely on the strong being responsible.</p>
    <footer class="post-info">
    </footer><!-- /.post-info -->
  </article>
    <br>
    <footer id="contentinfo" class="body">
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">
        <img alt="Creative Commons Licence" style="border-width:0"
            src="/theme/images/icons/cc.png" />
      </a><br />This work is licensed under a
      <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
    </footer><!-- /#contentinfo -->
  </body>
</html>